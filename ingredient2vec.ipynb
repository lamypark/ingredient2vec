{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load basic ingredients and compounds data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "path = 'data'\n",
    "ingr_info = path + os.sep + 'ingr_info.tsv'\n",
    "comp_info = path + os.sep + 'comp_info.tsv'\n",
    "ingr_comp = path + os.sep + 'ingr_comp.tsv'\n",
    "\n",
    "\n",
    "# {ingredient_id: [ingredient_name, ingredient_category]}\n",
    "def load_ingredients(path):\n",
    "    ingredients = {}\n",
    "    ingredients_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == '#':\n",
    "                pass\n",
    "            else:\n",
    "                line_split = line.rstrip().split('\\t')\n",
    "                ingredients_id = line_split[0]\n",
    "                ingredients_list = line_split[1:]\n",
    "                ingredients[ingredients_id] = ingredients_list\n",
    "    return ingredients\n",
    "\n",
    "# {compound_id: [compound_name, CAS_number]}\n",
    "def load_compounds(path):\n",
    "    compounds = {}\n",
    "    compounds_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == '#':\n",
    "                pass\n",
    "            else:\n",
    "                line_split = line.rstrip().split('\\t')\n",
    "                compounds_id = line_split[0]\n",
    "                compounds_list = line_split[1:]\n",
    "                compounds[compounds_id] = compounds_list\n",
    "    return compounds\n",
    "\n",
    "# {ingredient_id: [compound_id1, compound_id2, ...] }\n",
    "def load_relations(path):\n",
    "    relations = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == '#':\n",
    "                pass\n",
    "            else:\n",
    "                line_split = line.rstrip().split('\\t')\n",
    "                ingredient_id = line_split[0]\n",
    "                compound_id = line_split[1]\n",
    "                \n",
    "                if ingredient_id in relations:\n",
    "                    relations[ingredient_id].append(compound_id)\n",
    "                    \n",
    "                else:\n",
    "                    relations[ingredient_id] = [compound_id]\n",
    "                    \n",
    "    return relations\n",
    "\n",
    "ingredients = load_ingredients(ingr_info)\n",
    "compounds = load_compounds(comp_info)\n",
    "relations = load_relations(ingr_comp)\n",
    "\n",
    "def ingredient_to_category(tag, ingredients):\n",
    "    for ingr_id in ingredients:\n",
    "        if ingredients[ingr_id][0] == tag:\n",
    "            return ingredients[ingr_id][1]\n",
    "        else:\n",
    "            continue\n",
    "    return\n",
    "\n",
    "print ingredient_to_category('copaiba', ingredients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load train data and build train_corpus for Doc2Vec\n",
    "\n",
    "\"\"\"\n",
    "path = 'data'\n",
    "train_file = path + os.sep + 'ingredient2vec'\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                line_split = line.split(' ')\n",
    "                ingredient = line_split[0]\n",
    "                compounds = ' '.join(line_split[1:])\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(compounds), [ingredient])\n",
    "\n",
    "# Corpus tag to index\n",
    "def tag_to_index(tags, corpus):\n",
    "    for doc_id in range(len(corpus)):\n",
    "        if tags == corpus[doc_id].tags[0]:\n",
    "            return doc_id\n",
    "        else:\n",
    "            continue\n",
    "    return\n",
    "print tag_to_index('ruta_chalepensis_oil', train_corpus)        \n",
    "\n",
    "# Corpus index to tag                    \n",
    "def index_to_tag(index, corpus):\n",
    "    return corpus[index].tags\n",
    "    \n",
    "print index_to_tag(0, train_corpus)\n",
    "\n",
    "train_corpus = list(read_corpus(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh hold\n",
    "\n",
    "train_corpus_th10 = []\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    if len(train_corpus[doc_id].words) > 10:\n",
    "        train_corpus_th10.append(train_corpus[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load functions for plotting a graph\n",
    "\"\"\"\n",
    "\n",
    "# Prettify ingredients\n",
    "pretty_food = lambda s: ' '.join(s.split('_')).capitalize().lstrip()\n",
    "# Prettify cuisine names\n",
    "pretty_category = lambda s: ''.join(map(lambda x: x if x.islower() else \" \"+x, s)).lstrip()\n",
    "\n",
    "def make_plot_simple(name, points, labels, publish):\n",
    "    traces = []\n",
    "    traces.append(go.Scattergl(\n",
    "            x = points[:, 0],\n",
    "            y = points[:, 1],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                color = sns.xkcd_rgb[\"black\"],\n",
    "                size = 8,\n",
    "                opacity = 0.6,\n",
    "                #line = dict(width = 1)\n",
    "            ),\n",
    "            text = labels,\n",
    "            hoverinfo = 'text',\n",
    "        )\n",
    "        )\n",
    "                  \n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            showline=False,\n",
    "            autotick=True,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            showline=False,\n",
    "            autotick=True,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        )\n",
    "        )\n",
    "                  \n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    if publish:\n",
    "        plotter = py.iplot\n",
    "    else:\n",
    "        plotter = offline.plot\n",
    "    plotter(fig, filename=name + '.html')\n",
    "\n",
    "def make_plot(name, points, labels, legend_labels, legend_order, legend_label_to_color, pretty_legend_label, publish):\n",
    "    lst = zip(points, labels, legend_labels)\n",
    "    full = sorted(lst, key=lambda x: x[2])\n",
    "    traces = []\n",
    "    for legend_label, group in itertools.groupby(full, lambda x: x[2]):\n",
    "        group_points = []\n",
    "        group_labels = []\n",
    "        for tup in group:\n",
    "            point, label, _ = tup\n",
    "            group_points.append(point)\n",
    "            group_labels.append(label)\n",
    "        group_points = np.stack(group_points)\n",
    "        traces.append(go.Scattergl(\n",
    "            x = group_points[:, 0],\n",
    "            y = group_points[:, 1],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                color = legend_label_to_color[legend_label],\n",
    "                size = 8,\n",
    "                opacity = 0.6,\n",
    "                #line = dict(width = 1)\n",
    "            ),\n",
    "            text = ['{} ({})'.format(label, pretty_legend_label(legend_label)) for label in group_labels],\n",
    "            hoverinfo = 'text',\n",
    "            name = legend_label\n",
    "        )\n",
    "        )\n",
    "    # order the legend\n",
    "    ordered = [[trace for trace in traces if trace.name == lab] for lab in legend_order]\n",
    "    traces_ordered = flatten(ordered)\n",
    "    def _set_name(trace):\n",
    "        trace.name = pretty_legend_label(trace.name)\n",
    "        return trace\n",
    "    traces_ordered = list(map(_set_name, traces_ordered))\n",
    "    \n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    for index in range(50):\n",
    "        new_dict = dict(\n",
    "                x=points[:, 0][index],\n",
    "                y=points[:, 1][index],\n",
    "                xref='x',\n",
    "                yref='y',\n",
    "                text=labels[index],\n",
    "                showarrow=True,\n",
    "                arrowhead=7,\n",
    "                ax=0,\n",
    "                ay=-10\n",
    "            )\n",
    "        annotations.append(new_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            showline=True,\n",
    "            autotick=True,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            showline=True,\n",
    "            autotick=True,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        #annotations=annotations\n",
    "    )\n",
    "    fig = go.Figure(data=traces_ordered, layout=layout)\n",
    "    if publish:\n",
    "        plotter = py.iplot\n",
    "    else:\n",
    "        plotter = offline.plot\n",
    "    plotter(fig, filename=name + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train Doc2Vec Model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#dm/m,d50,n5,w5,mc5,s0.001,t3\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=5, iter=55)\n",
    "model.build_vocab(train_corpus_th10)\n",
    "%time model.train(train_corpus_th10, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check rank of inferred_vector\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(train_corpus[doc_id].tags[0])\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pick a random document from the test corpus and infer a vector from the model\n",
    "Top 10 Similar Vector\n",
    "\n",
    "\"\"\"\n",
    "doc_id = random.randint(0, len(train_corpus))\n",
    "\n",
    "print('Train Document ({}, {}): [{}]\\n'.format(doc_id, train_corpus[doc_id].tags[0], ' '.join(train_corpus[doc_id].words)))\n",
    "\n",
    "inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=10)\n",
    "for sim in sims:\n",
    "    print sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(train_corpus))\n",
    "inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Train Document ({}, {}): [{}]\\n'.format(doc_id, train_corpus[doc_id].tags[0], ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print label, sims[index]\n",
    "    #print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "\n",
    "doc_id = random.randint(0, len(train_corpus))\n",
    "\n",
    "inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Train Document ({}, {}): [{}]\\n'.format(doc_id, train_corpus[doc_id].tags[0], ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print label, sims[index]\n",
    "    #print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TSNE of Doc2Vec\n",
    "\n",
    "\"\"\"\n",
    "time_start = time.time()\n",
    "X = model.docvecs\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "print 't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "categories = []\n",
    "\n",
    "for doc_id in range(0, len(model.docvecs)):\n",
    "    labels.append(model.docvecs.index_to_doctag(doc_id))\n",
    "\n",
    "for label in labels:\n",
    "    categories.append(ingredient_to_category(label,ingredients))\n",
    "\n",
    "categories_color = list(set(categories))\n",
    "print categories_color\n",
    "\n",
    "category2color = {\n",
    "    'plant' :  sns.xkcd_rgb[\"purple\"],\n",
    "    'flower' : sns.xkcd_rgb[\"forest green\"],\n",
    "    'meat' : sns.xkcd_rgb[\"light pink\"],\n",
    "    'nut/seed/pulse' : sns.xkcd_rgb[\"mustard yellow\"],\n",
    "    'herb' : sns.xkcd_rgb[\"orange\"],\n",
    "    'alcoholic beverage' : sns.xkcd_rgb[\"magenta\"],\n",
    "    'plant derivative' : sns.xkcd_rgb[\"purple\"],\n",
    "    'fruit' : sns.xkcd_rgb[\"blue\"],\n",
    "    'dairy' : sns.xkcd_rgb[\"deep blue\"],\n",
    "    'cereal/crop' : sns.xkcd_rgb[\"sky blue\"],\n",
    "    'vegetable' : sns.xkcd_rgb[\"olive\"],\n",
    "    'animal product' : sns.xkcd_rgb[\"red\"],\n",
    "    'fish/seafood' : sns.xkcd_rgb[\"yellow\"],\n",
    "    'spice' : sns.xkcd_rgb[\"black\"],\n",
    "}\n",
    "\n",
    "category_order = [\n",
    "'plant',\n",
    "'flower',\n",
    "'meat',\n",
    "'nut/seed/pulse',\n",
    "'herb',\n",
    "'alcoholic beverage',\n",
    "'plant derivative',\n",
    "'fruit',\n",
    "'dairy',\n",
    "'cereal/crop',\n",
    "'vegetable',\n",
    "'animal product',\n",
    "'fish/seafood',\n",
    "'spice',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(name='food2vec_food_embeddings_tsne_th10',\n",
    "          points=X_tsne, \n",
    "          labels=labels, \n",
    "          legend_labels=categories, \n",
    "          legend_order=category_order, \n",
    "          legend_label_to_color=category2color, \n",
    "          pretty_legend_label=pretty_category,\n",
    "          publish=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "compound-level plotting\n",
    "\n",
    "\"\"\" \n",
    "X_comp = model[model.wv.vocab]\n",
    "tsne_comp = TSNE(n_components=2)\n",
    "X_tsne_comp = tsne_comp.fit_transform(X_comp)\n",
    "\n",
    "labels_comp =[]\n",
    "for comp in model.wv.vocab:\n",
    "    labels_comp.append(comp)\n",
    "\n",
    "make_plot_simple(name='food2vec_food_embeddings_tsne_comp',\n",
    "          points=X_tsne_comp, \n",
    "          labels=labels_comp, \n",
    "          publish=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
